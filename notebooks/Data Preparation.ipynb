{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f848d5-c4d6-4f38-959b-a5e4fbd16697",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import torch\n",
    "import pandas as pd\n",
    "import stat\n",
    "import numbers\n",
    "import pydicom\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "import re\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb7eca52-7920-45ba-a18a-f42fcb1544fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "Path().resolve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "447e09ab-0aa3-431e-8607-6be1d8246a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "nas_loc = Path('/home/buehlern/neocortex-nas')\n",
    "\n",
    "#data_loc = nas_loc / 'shared/Skelett'\n",
    "data_loc = nas_loc / 'shared/Skelett/HAND_NEU'\n",
    "\n",
    "foldercontents_cacheloc = Path('cache-hand/prep_foldercontents.pt')\n",
    "df_loc = Path('cache-hand/prep_df.pkl')\n",
    "df_allfiles_loc = Path('cache-hand/prep_df_allfiles')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd98078d-5cef-486b-8da5-71b97909eb19",
   "metadata": {},
   "outputs": [],
   "source": [
    "earlycols = ['patientid', 'bodypart', 'pixelarr_dtype',\n",
    "             'pixelarr_shape', 'pixelarr_non0count']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e618429e-e44c-4de6-901a-93ad158b06ac",
   "metadata": {},
   "source": [
    "# Step 1: Stat items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e8c8d8-5cc9-43ed-b48a-b99c663f1086",
   "metadata": {},
   "outputs": [],
   "source": [
    "def listitems(d):\n",
    "    print('rglobbing', d)\n",
    "    return sorted([x for x in d.rglob('*') if not '/__' in str(x)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb50af4-7baa-4a43-a3a3-702b4b02555a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def listitems_stated(d):\n",
    "    itemsraw = listitems(d)\n",
    "    print('stating items in', d)\n",
    "    res = []\n",
    "    for curres in itemsraw:\n",
    "        res.append((curres, curres.stat()))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b26545-ec5f-4898-8d13-28727296db6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "foldercontents = listitems_stated(data_loc)\n",
    "torch.save(foldercontents, foldercontents_cacheloc)\n",
    "print(\"saved to\", foldercontents_cacheloc.resolve())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb3dd00c-b077-4dfe-8768-809a062ba305",
   "metadata": {},
   "source": [
    "# Step 2: Read raw metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ead3ffb-9905-45dd-9b2f-36fa5df608db",
   "metadata": {},
   "outputs": [],
   "source": [
    "allitems = torch.load(foldercontents_cacheloc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e491eac-795d-4867-80c3-7118faae286f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_allfiles = pd.DataFrame([{'path': f, 'pathstr': str(f), 'stat': s} for (f, s) in allitems if stat.S_ISREG(s.st_mode)])\n",
    "df_allfiles.set_index('pathstr', inplace=True)\n",
    "df_allfiles['path_withoutsquarebrackets'] = df_allfiles.index.str.replace(r'\\[\\d+\\]$', r'', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8708d484-0732-4db7-a538-4519917d94da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_metainfos(pathstr, read_fulldcm=True):\n",
    "    output_dict = {'header': '', 'errors': ''} \n",
    "    \n",
    "    try:\n",
    "        header = pydicom.dcmread(pathstr, stop_before_pixels=True)\n",
    "        output_dict = {'header': header, 'errors': ''}\n",
    "    except Exception as e:\n",
    "        output_dict['errors'] += f'{repr(e)}\\n'\n",
    "    \n",
    "    if read_fulldcm:\n",
    "        try:\n",
    "            dcm = pydicom.dcmread(pathstr)\n",
    "            if repr(set(dcm.keys()) - set(header.keys())) != '{(7fe0, 0010)}':\n",
    "                output_dict['errors'] += f'unusual key difference: set(dcm.keys()) - set(header.keys())\\n'\n",
    "        except Exception as e:\n",
    "            output_dict['errors'] += f'{repr(e)}\\n'\n",
    "        \n",
    "        try:\n",
    "            pixelarr = dcm.pixel_array\n",
    "            output_dict['pixelarr_dtype'] = pixelarr.dtype\n",
    "            output_dict['pixelarr_shape'] = pixelarr.shape\n",
    "            output_dict['pixelarr_min'] = np.min(pixelarr)\n",
    "            output_dict['pixelarr_max'] = np.max(pixelarr)\n",
    "            output_dict['pixelarr_mean'] = np.mean(pixelarr)\n",
    "            output_dict['pixelarr_std'] = np.std(pixelarr)\n",
    "            output_dict['pixelarr_non0count'] = np.count_nonzero(\n",
    "                pixelarr)\n",
    "            pixelarr_non0 = pixelarr[pixelarr != 0]\n",
    "            output_dict['pixelarr_non0min'] = np.min(pixelarr_non0)\n",
    "            output_dict['pixelarr_non0mean'] = np.mean(\n",
    "                pixelarr_non0)\n",
    "            output_dict['pixelarr_non0std'] = np.std(pixelarr_non0)\n",
    "        except Exception as e:\n",
    "            output_dict['errors'] += f'{repr(e)}\\n'\n",
    "    \n",
    "    if output_dict['errors'] != '':\n",
    "        print(pathstr, output_dict['errors'])\n",
    "    \n",
    "    return pathstr, output_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e657be4b-8ad8-4eb7-9a12-515f01830380",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_keys = read_metainfos(list(df_allfiles.index)[0])[1].keys()\n",
    "df_allfiles = df_allfiles.reindex(columns=list(df_allfiles.columns) + list(new_keys))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44e5bb83-b7af-4799-b496-5d01b3779c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for new_key in new_keys:\n",
    "#     df_allfiles[new_keys] = [np.nan] * len(df_allfiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd6ed892-9e9d-4160-9a1a-70e3c90aad0e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for pathstr, output_dict in map(read_metainfos, list(df_allfiles.index)):\n",
    "    for k, v in output_dict.items():\n",
    "        if not isinstance(v, numbers.Number):\n",
    "            # ease into setting the cellvalue to an object\n",
    "            df_allfiles.at[pathstr, k] = ''\n",
    "        df_allfiles.at[pathstr, k] = v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "549062a9-2f6b-4faf-b505-0fdc9523b545",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_allfiles.to_pickle(df_allfiles_loc)\n",
    "print('wrote df of len', len(df_allfiles))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08af06a5-5210-44e4-8c94-a64308db9f31",
   "metadata": {},
   "source": [
    "# Step 3: Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc46526-f8d1-4257-beae-2eee36b68bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('loading df_allfiles')\n",
    "df_allfiles = pd.read_pickle(df_allfiles_loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c227da-d686-4d3c-aaa2-16a1cc13b386",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleanup tool\n",
    "print('ensuring no cleanup due')\n",
    "planned_for_deletion = {}\n",
    "for i, row in tqdm(list(df_allfiles.iterrows())):\n",
    "    imagetype = []\n",
    "    try:\n",
    "        imagetype = row['header'].ImageType\n",
    "        if 'DRAWING' in imagetype:\n",
    "            planned_for_deletion[row['path']] = f'{imagetype=}'\n",
    "    except AttributeError:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b3e9ea-f57d-43ff-a48d-83d8244b0864",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(planned_for_deletion) > 0:\n",
    "    for i, row in tqdm(list(df_allfiles.iterrows())):\n",
    "        if row['path'] not in planned_for_deletion:\n",
    "            continue\n",
    "            \n",
    "        ok = False\n",
    "        for _, innerrow in df_allfiles.iterrows():\n",
    "            if (not isinstance(innerrow['header'], str)) and innerrow['header'].StudyInstanceUID == row['header'].StudyInstanceUID and innerrow['header'].PatientID == row['header'].PatientID and  innerrow['path'] not in planned_for_deletion:\n",
    "                ok = True\n",
    "                break\n",
    "        #assert ok\n",
    "        if not ok:\n",
    "            print(\"ASSERTION ok:\", ok)\n",
    "\n",
    "\n",
    "    Path('cleanupscript.sh').write_text(\n",
    "        '\\n'.join(\n",
    "            f\"rm '{k}'  # reason: {v}\"\n",
    "            for k, v in planned_for_deletion.items()\n",
    "        )\n",
    "    )\n",
    "    print('cleanup due, cf cleanupscript.sh ; rerun this script after the cleanup and removing the old cache')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "175f3e64-f4df-4cc9-9c0e-d9e6385567c2",
   "metadata": {},
   "source": [
    "# Step 4: Format and drop rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb294e1-1da3-4251-a3f7-1ad846cd4d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_allfiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44dfab4a-f698-4019-a7d4-07c2ed1ad59c",
   "metadata": {},
   "outputs": [],
   "source": [
    "beforelen = len(df)\n",
    "df = df[df.index == df['path_withoutsquarebrackets']]\n",
    "print(\n",
    "    f'dropped {beforelen-len(df)}/{beforelen}={(beforelen-len(df))/beforelen:.4f} (square bracket duplicates)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef6a7db-2a5d-43dc-9388-ea109ebb3f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "beforelen = len(df)\n",
    "df = df.iloc[(np.nonzero(df['pixelarr_shape'].fillna(0).to_numpy()))[0]]\n",
    "print(\n",
    "    f'dropped {beforelen-len(df)}/{beforelen}={(beforelen-len(df))/beforelen:.4f} (no pixel data)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "169a16e4-af48-4119-a174-85c11e8d3d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['patientid'] = [path.parent.parent.parent.name for path in df['path']]\n",
    "df['bodypart'] = [path.parent.parent.parent.parent.name for path in df['path']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ea2cbb-8f54-4773-8b35-41dc7ecc9a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# expand df columns by all dicom header fields\n",
    "dicom_headers_counter = Counter()\n",
    "\n",
    "for header in tqdm(list(df['header'])):\n",
    "    dicom_headers_counter.update(header.keys())\n",
    "\n",
    "dcmcols = [f'dcm_{pydicom.datadict.keyword_for_tag(k)}' for k in sorted(\n",
    "    dicom_headers_counter)]\n",
    "\n",
    "df = df.reset_index()\n",
    "df = df.reindex(columns=earlycols +\n",
    "                dcmcols + [x for x in list(df.columns) if x not in earlycols])\n",
    "\n",
    "# df = df.style.hide('header', axis='columns')\n",
    "\n",
    "for col in tqdm(dcmcols):\n",
    "    # print('fetching all ', col)\n",
    "    tag = pydicom.datadict.tag_for_keyword(col[len('dcm_'):])\n",
    "    df[col] = [\n",
    "        header[tag].value if tag in header else np.nan for header in df['header']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c55b0df-6022-42c2-aef7-e3e313ec44dc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# FILTER OUT UNUSUAL dcm_ImageType s\n",
    "beforelen = len(df)\n",
    "df['dcm_ImageType_str'] = [repr(x) for x in df['dcm_ImageType']]\n",
    "valcounts = df['dcm_ImageType_str'].value_counts()\n",
    "print(valcounts)\n",
    "count_images_except_top2imagetypes = valcounts.sum() - valcounts.nlargest(2).sum()\n",
    "print('count images, except top 2: ',\n",
    "      count_images_except_top2imagetypes)\n",
    "keep_imagetypes = set(valcounts.nlargest(2).index)\n",
    "\n",
    "df_dropimagetypes = df[~df['dcm_ImageType_str'].isin(keep_imagetypes)]\n",
    "df = df[df['dcm_ImageType_str'].isin(keep_imagetypes)]\n",
    "\n",
    "for i, droprow in df_dropimagetypes.iterrows():\n",
    "    subdf = df[(df['dcm_StudyInstanceUID'] == droprow['dcm_StudyInstanceUID']) & (\n",
    "        df['dcm_PatientID'] == droprow['dcm_PatientID'])]\n",
    "    #assert len(subdf) > 0\n",
    "    if not len(subdf) > 0:\n",
    "        print(\"ASSERTION len(subdf) > 0:\", len(subdf) > 0)\n",
    "\n",
    "print(f'dropped {beforelen-len(df)}/{beforelen}={(beforelen-len(df))/beforelen:.4f} (unusual image type, all StudyInstanceUID (and PatientID) s remain present)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b35cb2e4-728a-44e9-bcb1-090ee71ced02",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "beforelen = len(df)\n",
    "df_dropimageshape = df[[x[1] == 650 for x in df['pixelarr_shape']]]\n",
    "df = df[[x[1] != 650 for x in df['pixelarr_shape']]]\n",
    "for i, droprow in df_dropimagetypes.iterrows():\n",
    "    subdf = df[(df['dcm_StudyInstanceUID'] == droprow['dcm_StudyInstanceUID']) & (\n",
    "        df['dcm_PatientID'] == droprow['dcm_PatientID'])]\n",
    "    #assert len(subdf) > 0\n",
    "    if not len(subdf) > 0:\n",
    "        print(\"ASSERTION len(subdf) > 0:\", len(subdf) > 0)\n",
    "print(f'dropped {beforelen-len(df)}/{beforelen}={(beforelen-len(df))/beforelen:.4f} (unusual image shape, all StudyInstanceUID (and PatientID) s remain present)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2926ff9e-a5eb-4711-abe6-447338c0368f",
   "metadata": {},
   "outputs": [],
   "source": [
    "beforelen = len(df)\n",
    "# 2 or 3 dimensions\n",
    "#assert all([2 <= len(x) <= 3 for x in df['pixelarr_shape']])\n",
    "print(\"ASSERTION all([2 <= len(x) <= 3 for x in df['pixelarr_shape']])\", all([2 <= len(x) <= 3 for x in df['pixelarr_shape']]))\n",
    "# rgb if 3 dimensions dimensions\n",
    "#assert all([x[2] == 3 for x in df['pixelarr_shape'] if len(x) == 3])\n",
    "print(\"ASSERTION all([2 <= len(x) <= 3 for x in df['pixelarr_shape']])\", all([2 <= len(x) <= 3 for x in df['pixelarr_shape']]))\n",
    "df = df[[len(x) != 3 for x in df['pixelarr_shape']]]\n",
    "print(f'dropped {beforelen-len(df)}/{beforelen}={(beforelen-len(df))/beforelen:.4f} (rgb images; all images are 2d now (i.e. no color dimension))')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f5657a-3fc3-4497-87ee-e79869adabb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_pickle(df_loc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b109d6f-a7bc-49ab-8678-d64c38f355c0",
   "metadata": {},
   "source": [
    "# Step 5: Further formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b403a948-0182-41f1-bcb1-fd61a356095b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('reading df.pkl')\n",
    "df_loaded = pd.read_pickle(df_loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f10a2e7a-cad0-4aab-b078-76a8dc7399e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dcmcols = [x for x in df_loaded.columns if x.startswith('dcm_')]\n",
    "pivotmask = earlycols + dcmcols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faec05af-5722-49e3-ac82-d50e6554f4ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_loaded['dcm_AnatomicRegionSequence_str'] = [','.join((x[(0x8, 0x104)].value for x in seq)\n",
    "                                                 if not seq != seq else '').lower()\n",
    "                                        for seq in df_loaded['dcm_AnatomicRegionSequence']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b17951-cc17-4c49-a517-d593b92dc09d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_loaded['dcm_BodyPartExamined_str'] = [(seq if not seq != seq else '').lower()\n",
    "                                  for seq in df_loaded['dcm_BodyPartExamined']]\n",
    "\n",
    "df_labelcomparison = pd.pivot_table(df_loaded, index=['dcm_BodyPartExamined_str'], columns=['bodypart'], values=['patientid'],\n",
    "                                    sort=False, aggfunc=lambda x: x.count())\n",
    "\n",
    "df_labelcomparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e394d0-6afb-4256-8c80-001e7dc3f5d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "vowel_char_map = {ord('ä'): 'ae',\n",
    "                  ord('ö'): 'oe',\n",
    "                  ord('ü'): 'ue',\n",
    "                  ord('Ä'): 'Äe',\n",
    "                  ord('Ö'): 'Oe',\n",
    "                  ord('Ü'): 'Ue',\n",
    "                  ord('ß'): 'ss'}\n",
    "\n",
    "df_loaded['oldbodypart'] = df_loaded['bodypart']\n",
    "df_loaded['bodypart'] = [re.sub(r'^DX[-_]', '', x).translate(vowel_char_map).lower()\n",
    "                        for x in df_loaded['bodypart']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06296b92-6151-41fb-b06f-cc99d04ebabd",
   "metadata": {},
   "source": [
    "# Step 6: Findings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b43603d-a39e-4660-b411-c1c74c3db93b",
   "metadata": {},
   "outputs": [],
   "source": [
    "findings_loc = nas_loc / 'shared/Befundexport'\n",
    "all_findings = sorted(findings_loc.rglob('Befunde_*/*.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "381ceb2a-1a58-49c0-a750-10dc1eeaa9cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_findings = dict(zip([re.fullmatch(r'Befund__?(.+)\\.txt', x.name).group(1) for x in all_findings], all_findings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f098e6a-138a-4ec8-8197-92d33bd69b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "keyerrors = []\n",
    "df['findingspath'] = ''\n",
    "df['findings'] = ''\n",
    "df['examinationid'] = [x.parent.parent.name for x in df['path']]\n",
    "for i, row in tqdm(df.iterrows(), total=len(df)):\n",
    "    try:\n",
    "        findingsfile = all_findings[row['examinationid']]\n",
    "        df.loc[i, 'findingspath'] = findingsfile\n",
    "\n",
    "        findings = findingsfile.read_text('utf8')\n",
    "        assert len(findings.strip()) > 0\n",
    "        df.loc[i, 'findings'] = findings\n",
    "    except KeyError:\n",
    "        keyerrors.append(row)\n",
    "\n",
    "print('NO FINDINGS FOR ', len(keyerrors), ' OF ', len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4687b93-2789-40b5-8c0e-fb398da1ba29",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.to_pickle(df, df_loc)\n",
    "print('WROTE FINAL DF (including findings)')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
