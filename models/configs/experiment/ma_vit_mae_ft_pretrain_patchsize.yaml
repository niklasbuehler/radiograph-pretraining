# @package _global_

defaults:
  - ma_vit_mae_ft_pretrain

trainer:
  accumulate_grad_batches: 171 # keep the same effective batch_size
  
model:
  patch_size: 32

data:
  batch_size: 6 # decrease batch size (due to memory constraints)
  num_workers: 4